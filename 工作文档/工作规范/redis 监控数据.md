# Redis 监控指标与异常分析
Redis 的监控是保障其稳定运行的核心环节，通过对**CPU、内存、网络流量、QPS、Key 过期/置换、主从延迟**等关键指标的监控，可快速定位性能瓶颈和异常问题。本文梳理了各核心监控指标的异常表现、根因分析及应对思路。

## 一、CPU 指标偏高
Redis 是单线程（核心逻辑）架构，CPU 使用率过高会直接导致请求响应延迟、吞吐量下降，需重点排查以下原因：

### 1. 执行高消耗命令
- **典型命令**：`KEYS *`（全量遍历键，阻塞主线程）、`HGETALL`/`HMGET`/`HMSET`（批量操作哈希）、`MGET`/`MSET`（批量读写字符串）等。
  - 这类命令会一次性处理大量数据，占用主线程时间，导致其他请求阻塞。
- **处理思路**：
  1. 禁用`KEYS *`，改用`SCAN`（分批遍历，非阻塞）；
  2. 将批量操作拆分为多次小批量请求（如`MGET`拆分为多次`GET`）；
  3. 通过`slowlog get`查看慢查询日志，定位高消耗命令的调用方。

### 2. 大 Key 访问
- **问题表现**：对大 Key（如超大字符串、包含百万级元素的哈希/列表）的高频访问，会显著增加 CPU 负载，同时导致读网络流量飙升。大 Key 也易形成热点，进一步加剧 CPU 压力。
- **处理思路**：
  1. 通过`redis-cli --bigkeys`工具定位大 Key；
  2. 拆分大 Key（如将超大哈希拆分为多个小哈希，按业务维度分片）；
  3. 降低大 Key 的访问频率，或通过缓存预热、本地缓存分担压力。

### 3. 短连接频繁建立
- **问题表现**：客户端频繁创建/关闭 Redis 连接，Redis 需消耗大量资源处理连接握手、认证等操作，导致 CPU 使用率升高。
- **处理思路**：
  1. 客户端启用连接池（如 Jedis Pool、Redisson），复用连接，减少短连接数量；
  2. 结合 Redis 连接数监控曲线，确认连接数是否随请求量突发增长。

### 4. 备份操作频繁
- **问题表现**：AOF 重写（rewrite）或 RDB 备份频繁触发，Redis 会fork子进程执行磁盘写入，子进程的 CPU 占用会间接导致主进程性能下降，同时磁盘 IO 也会抢占 CPU 资源。
- **处理思路**：
  1. 调整备份策略：降低 RDB 备份频率（如从每小时一次改为每天一次），或调整 AOF 重写的触发阈值（如`auto-aof-rewrite-min-size`调大）；
  2. 在业务低峰期执行备份操作，减少对高峰期的影响；
  3. 优化服务器磁盘性能（如使用 SSD），加快备份文件的写入速度。

### 补充说明
本文环境未使用 Redis 集群模式，因此**热 Key 导致的集群数据倾斜**问题无需考虑（集群模式下需通过热 Key 分片、本地缓存解决）。

## 二、可用内存指标
Redis 的可用内存直接影响其缓存能力和稳定性，需重点监控内存使用率的变化：

### 1. 异常阈值
当可用内存**小于总内存的 50%** 时，需引起注意；若可用内存持续低于 20%，则属于高风险状态。

### 2. 内存不足的影响
- Key 占用内存过多，会显著增加 RDB 备份和 AOF 重写的时间，导致 Redis 性能波动；
- 内存耗尽时，Redis 会触发键置换（evict），频繁的置换操作会进一步消耗 CPU 和 IO 资源。

### 3. 处理思路
1. **清理无效数据**：删除过期未清理的 Key、无用的缓存数据，释放内存；
2. **拆分 Redis 实例**：将不同业务的缓存数据拆分到多个 Redis 实例，分散内存压力；
3. **扩容服务器内存**：直接升级 Redis 服务器的物理内存，扩大可用内存空间；
4. **优化内存配置**：调整`maxmemory-policy`（如改为`volatile-lru`，仅置换过期 Key），避免核心数据被置换。

## 三、网络流量指标
网络流量是反映 Redis 负载的重要指标，分为**读流量**和**写流量**，需结合业务场景分析：

### 1. 监控价值
- 判断 Redis 的请求负载强度：流量持续飙升通常意味着请求量或数据传输量增加；
- 关联其他指标：结合 CPU、QPS 指标，可区分高流量是因请求数量多，还是因大 Key 传输导致的数据量过大。

### 2. 异常分析
- **读流量突增**：多为大 Key 读取、批量数据导出或高频查询导致；
- **写流量突增**：多为批量写入（如`MSET`、批量哈希更新）、大 Key 写入或业务峰值数据入库导致。

### 3. 处理思路
- 针对大 Key 导致的流量飙升：按前文方法拆分大 Key；
- 针对批量操作导致的流量波动：将批量操作拆分为小批量，分散流量压力；
- 限制非核心业务的高频访问：通过限流策略降低非核心请求的频率，保障核心业务的网络带宽。

## 四、QPS 指标
QPS（每秒查询率）是 Redis 吞吐量的核心指标，需结合**CPU 使用率**和**网络流量**综合分析：

### 1. 异常场景分析
- **QPS 高 + CPU 低 + 网络流量低**：多为简单小请求（如`GET`/`SET`单个小 Key），Redis 可正常承载，无需优化；
- **QPS 高 + CPU 高 + 网络流量高**：多为大 Key 操作或高消耗命令导致，需重点优化命令和 Key 结构；
- **QPS 低 + CPU 高 + 网络流量低**：多为慢查询（如`KEYS *`、`SMEMBERS`）阻塞主线程，需定位并禁用慢查询。

### 2. 优化思路
- 提升 QPS 上限：通过开启 Redis 多线程 IO（Redis 6.0+ 支持）、优化服务器网络（如万兆网卡）提升吞吐量；
- 降低无效 QPS：减少重复请求、缓存穿透/击穿导致的无效查询，通过布隆过滤器等手段优化。

## 五、Key 过期与置换指标
Redis 提供了`expired`（每秒过期 Key 数）和`evicted`（每秒置换 Key 数）两个指标，反映内存中 Key 的生命周期管理情况：

### 1. Expired（Key 过期）
- **异常表现**：每秒过期 Key 数突增（集中过期），会导致 Redis 主线程消耗资源处理过期 Key，引发性能波动。
- **根因**：业务侧批量创建了相同过期时间的 Key，导致集中过期。
- **处理思路**：
  1. 优化 Key 的过期策略：为批量 Key 添加**随机过期时间偏移**（如在基础过期时间上加减 10 分钟），分散过期压力；
  2. 启用 Redis 惰性删除+定期删除机制，减少集中过期的影响。

### 2. Evicted（Key 置换）
- **异常表现**：每秒置换 Key 数大于 0 且持续增长，说明 Redis 可用内存不足，已触发内存置换策略。
- **处理思路**：
  1. 优先扩容内存或拆分实例（参考本文第二部分）；
  2. 调整置换策略：避免使用`allkeys-lru`（置换所有 Key），改用`volatile-lru`（仅置换过期 Key），保护核心业务数据；
  3. 清理无效数据，释放内存空间，减少置换频率。

## 六、Redis 主从延迟指标
Redis 主从复制延迟是主从架构的核心监控指标，延迟过高会导致从库数据不一致，影响读写分离和故障切换的可靠性。

### 1. 主从延迟的监控方式
- 通过`INFO replication`命令查看：`master_repl_offset`（主库偏移量）和`slave_repl_offset`（从库偏移量）的差值即为延迟字节数；
- 通过 Redis 监控工具（如 Prometheus + Grafana）查看主从延迟的时间差曲线。

### 2. 主从延迟升高的常见原因
1. **主库写压力过大**：主库执行大事务、批量写入或高消耗写命令，从库复制数据的速度跟不上主库；
2. **网络问题**：主从节点之间的网络延迟高、带宽不足，导致复制数据传输缓慢；
3. **从库性能瓶颈**：从库 CPU/内存/磁盘 IO 资源不足，或从库执行慢查询、备份操作，导致复制线程（IO 线程、同步线程）阻塞；
4. **大 Key 复制**：主库的大 Key 同步到从库时，会消耗大量网络和 CPU 资源，导致延迟陡增；
5. **从库配置不当**：如从库开启了`repl-diskless-sync`（无盘复制）但网络不佳，或从库`slave-read-only`关闭后被写入数据，占用复制资源。

### 3. 主从延迟的优化思路
1. **优化主库写操作**：拆分大事务、减少批量写入，降低主库写压力；
2. **提升主从网络性能**：将主从节点部署在同一机房，使用高速网络，避免跨地域低带宽复制；
3. **优化从库性能**：
   - 从库仅用于复制和读查询，禁止在从库执行高消耗命令或备份操作；
   - 为从库扩容 CPU、内存，提升数据同步的处理能力；
4. **拆分大 Key**：避免大 Key 导致的复制阻塞，参考本文第一部分的大 Key 优化方法；
5. **调整复制配置**：
   - 开启主从复制的增量同步，避免全量同步；
   - 对大内存实例，关闭从库的 AOF 重写（若从库仅用于读，可禁用 AOF），减少磁盘 IO 压力。