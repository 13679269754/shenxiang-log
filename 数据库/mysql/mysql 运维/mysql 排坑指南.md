| operator | createtime | updatetime |
| ---- | ---- | ---- |
| shenx | 2023-12月-27 | 2023-12月-27  |

---

[建议收藏|MySQL DBA 防坑指南](https://mp.weixin.qq.com/s/iy9mAwahHWo4V3tyYGm6jw)

# MySQL DBA 防坑指南
本文由茹憶老师根据叶金荣（Oracle MySQL ACE Director）的直播内容整理而成，涵盖 MySQL 运维过程中常见的 19 个核心坑点及解决方案，建议收藏备用。

## 1. MySQL 连接数问题
- **核心说明**：`max_connections` 参数控制 MySQL 最大连接数，默认值 151（MySQL 5.5/5.6/5.7 一致），上限 100000，生产环境默认值完全不足用。
- **故障现象**：连接数超出限制时，会出现 `too many connections` 报错，业务无法连接数据库。
- **解决方案**：
  1. 生产环境建议设置为 5000-10000（无固定值，需结合业务压力调整）；
  2. 做好连接数监控，避免连接数满引发故障；
  3. 分析连接数过高原因：是否存在大量短连接、连接未正常关闭、代码逻辑问题等。

## 2. MySQL 文件句柄设置
- **核心说明**：文件句柄（file handle）是操作系统识别打开文件的唯一标识，`open_file_limits` 控制 mysqld 进程最大文件句柄数。
- **故障现象**：打开文件句柄数超过系统限制，会引发各类连锁错误（取决于当前操作的文件类型）。
- **解决方案**：
  1. 通过 `setrlimit` 系统调用初始化 mysqld 进程的文件句柄数；
  2. 编辑 `/etc/sysctl.conf`，调整 `fs.file-max` 参数，增加 Linux 系统全局打开文件限制。

## 3. 注意 SQL 隐式转换的坑
- **核心说明**：隐式转换指 `WHERE` 条件中值与对应列的数据类型不一致（如 `where id='123'` 且 `id` 为 `bigint`，或 `where code=100` 且 `code` 为 `varchar`）。
- **潜在风险**：
  1. 导致索引失效，查询性能骤降；
  2. 产生非预期查询结果。
- **解决方案**：开发规范中明确要求，避免 `WHERE` 条件中的隐式类型转换，确保值与列数据类型一致。

## 4. SQL 一会走索引、一会不走索引
- **核心现象**：同一 SQL 之前能走索引、查询快速，突然触发慢查询报警，执行时间长达十多秒。
- **根本原因**：MySQL 优化器判断索引扫描行数过多（约 20% 以上）时，会选择全表扫描（优化器并非绝对智能）。
- **示例场景**：查询小众用户的评论表会走索引，但查询大 V 账号的评论（涉及数百万条数据）时，优化器会切换为全表扫描。
- **解决方案**：结合业务场景优化，如拆分大表、调整索引设计、强制索引（谨慎使用）等。

## 5. 自增键重启后回溯问题
- **版本差异**：
  - MySQL 8.0+：自增值已实现持久化，重启后可恢复为重启前的值；
  - MySQL 5.7 及之前：自增值仅保存在内存中，未持久化。
- **故障现象**：假设表中最大 `id=10`，`AUTO_INCREMENT=11`，删除 `id=10` 后重启实例，`AUTO_INCREMENT` 会变为 10，导致自增值回溯。
- **解决方案**：若使用 MySQL 5.7 及以下版本，需注意自增值回溯风险，必要时通过业务逻辑兜底（如记录当前最大自增值）。

## 6. 自增键用完怎么办
- **核心风险**：自增键通常设为 `int` 类型（范围：-21 亿 ~ 21 亿），频繁插入/删除数据的表可能耗尽上限，导致业务无法正常写入。
- **补充说明**：自增键可能因唯一主键冲突、事务回滚、批量插入申请自增值等原因出现不连续。
- **解决方案**：
  1. 预估数据量可能达上限时，将自增键类型改为 `bigint unsigned`（8 字节，范围更大）；
  2. 监控自增键使用率，达 80% 时触发报警，提前扩容。

## 7. 大表删除 hang 的问题
- **核心风险**：直接对大表执行 `DROP TABLE` 可能导致 MySQL Hang 住，影响业务。
- **前提条件**：表需为独立表空间。
- **安全删除步骤**：
  1. 创建硬链接：`ln pay_bills.ibd pay_bills.ibd_hdlk`（仅创建文件引用，不占用额外空间）；
  2. 执行表删除：`DROP TABLE pay_bills;`（仅删除原文件引用，物理文件未删除，IO 波动小）；
  3. 安装 `truncate` 工具：`yum install coreutils -y`；
  4. 分步删除硬链接文件（避免一次性删除引发 IO 压力）：
     ```bash
     # 示例：175G 文件分步缩减
     TRUNCATE=/usr/bin/truncate
     for i in `seq 175 -2 1`; do
       $TRUNCATE -s ${i}G pay_bills.ibd_hdlk
       sleep 1
     done
     ```
  5. 最终删除硬链接：`rm -f pay_bills.ibd_hdlk`。

## 8. Adaptive Hash Index（AHI）引发的问题
- **核心说明**：AHI 是 InnoDB 自动为热点页建立的哈希索引（查找时间复杂度 O(1)，比 B+ 树更快），但 `DROP TABLE` 时会触发 AHI 删除。
- **故障现象**：`DROP TABLE` 过程中，大量线程处于 `OPENING TABLES` 状态，删除耗时极长（删除 AHI 需持有数据字典的互斥锁、读写锁）。
- **解决方案**：
  1. `DROP TABLE` 时临时关闭 AHI 功能；
  2. 若业务场景允许，可永久关闭 AHI 功能。

## 9. MHA 切换 VIP 的问题
- **核心说明**：MHA 是经典的 MySQL 高可用切换工具，默认通过 VIP 漂移实现主从切换。
- **潜在风险**：因网卡问题可能导致 VIP 漂移失败，进而引发切换失败。
- **优化方案**：运维能力较强的公司可二次开发 MHA，将 VIP 漂移改为 DNS 切换，业务通过连接 DNS 域名实现高可用（避免网卡依赖）。

## 10. pt-archiver 迁移为什么少了一条数据
- **核心说明**：`pt-archiver` 是 Percona 工具集的轻量级大表归档工具，默认启用 `--safe-auto-increment=yes` 参数。
- **故障原因**：该参数会避免归档自增列（AUTO_INCREMENT）最大值对应的行，防止数据库重启后自增值异常，导致最后一条数据无法归档。
- **解决方案**：根据业务需求，手动指定 `--no-safe-auto-increment` 参数（需确认自增值无重启依赖）。

## 11. pt-osc 和 ghost 变更丢数据的问题
- **核心场景**：使用 `pt-osc`（Percona Toolkit）或 `gh-ost` 执行在线 DDL 时，可能出现数据丢失，尤其在添加唯一索引时风险极高。
- **测试结果**（基于测试表 `ddltest`，含 `id` 自增主键和 `name` 字段）：

| SQL 操作 | pt-osc 2.2.7 | Gh-ost | 新字段结果值 |
|----------|--------------|--------|--------------|
| add age int not null | 执行失败 | 执行成功（不丢数据） | int 类型 0；char 类型；datetime 0000-00-00 00:00:00 |
| add age int not null, add unique index uniq_age(age) | 执行失败 | 执行成功（丢数据，只剩第一条） | int 类型 0；char 类型 "" |
| add age int not null default 1, add unique index uniq_age(age) | 执行成功（丢数据，只剩第一条） | 执行成功（丢数据，只剩第一条） | 指定 default 值 |
| add unique index uniq_name(name) | 执行成功（丢数据，第二个重复值丢失） | 执行成功（丢数据，第二个重复值丢失） | - |

- **核心结论**：
  1. 加字段设 `not null` 无 default 值：pt-osc 报错（不丢数据），gh-ost 自动填充默认值（不丢数据）；
  2. 加唯一索引：两者均成功，但会丢失重复值之后的所有数据；
  3. 加 `not null` 字段（无 default）+ 唯一索引：pt-osc 报错（不丢数据），gh-ost 成功（丢数据）；
  4. 加 `not null` 字段（有 default）+ 唯一索引：两者均成功（丢数据）；
  5. 字段允许 null + 唯一索引：不丢数据（null 不视为重复值）。
- **解决方案**：
  1. 完善 SQL 军规：`not null` 字段必须带 default 值，`not null` 字段禁止加唯一索引；
  2. 优化审核流程：新增唯一索引的 SQL 需 DBA 审核，禁止开发自动执行；
  3. 单独处理唯一索引：走 online ddl 模式，尽量不使用 pt-osc/gh-ost；
  4. 升级工具版本：Percona Toolkit 3.0.13+ 支持 `--check-unique-key-change` `--check-alter` 参数，可提前检查唯一索引变更并报错。

## 12. 数据库拆分引发的删库事件
- **真实案例**：通过搭建同步备库拆分数据库（备库仅同步需拆分的库），拆分完成后在老库删除已拆分的数据库，导致新库对应的数据库也被删除。
- **故障原因**：新库未断开与老库的同步关系，老库的删除操作通过同步链路同步到新库。
- **解决方案**：
  1. 运维操作前编写详细步骤，关键步骤（如删库、删表）需双人核对；
  2. 数据库拆分完成后，务必先断开新库与老库的同步关系，再执行老库的清理操作。

## 13. HA 没有切换/监控没有正常报警
- **核心风险**：依赖 HA 平台、监控平台保障高可用，但这些工具本身可能存在单点故障，导致数据库故障时无法切换、监控报警失效。
- **解决方案**：
  1. 对 HA 平台、备份平台、监控平台自身的服务及 Agent 做监控；
  2. 避免工具单点，必要时搭建冗余架构。

## 14. df 看空间越来越少，du 却没有发现大文件
- **故障现象**：`df -hT` 显示磁盘满，但 `du -sh *` 找不到大文件。
- **根本原因**：使用 `rm` 删除大文件后，若仍有进程打开该文件且未关闭句柄，Linux 内核不会释放磁盘空间。
- **解决方案**：
  1. 查找占用已删除文件的进程：`lsof -n | grep deleted`；
  2. 杀死对应进程释放空间：`kill -9 进程号`；
  3. 批量处理命令：`lsof | awk '/deleted/{print $2}' | xargs kill -9`；
  4. 额外检查：是否有 vim 进程打开大文件（也会导致该问题）。

## 15. 死锁要紧么，需要注意什么
- **核心判断**：偶尔低频的死锁影响不大，高频死锁会严重影响业务。
- **分析方法**：执行 `show engine innodb status` 命令获取锁信息，结合业务场景和代码逻辑分析死锁原因（最好能复现死锁）。
- **处理原则**：高频死锁需针对性优化（如调整事务执行顺序、缩小事务范围、优化索引等）。

## 16. text 等大对象类型有什么风险
- **潜在风险**：
  1. `text/blob` 大字段会引发 InnoDB 页分裂，影响查询和写入性能；
  2. 占用更多物理磁盘空间，不合理使用会造成磁盘浪费。
- **参考建议**：谨慎使用大对象类型，必要时可将大字段拆分到独立表中。

## 17. CPU %user 为什么特别高
- **核心原因**：MySQL 服务器 CPU `%user` 占比高（通常 95% 以上），大概率是索引使用不当导致。
- **排查方向**：重点关注慢 SQL，尤其是执行状态为 `send data`、`creating sort index`、`copying to tmp table`、`creating tmp table` 的 SQL，跟踪并优化。

## 18. 查询被 hang 住了，什么原因
- **排查维度**：查询 hang 住需从系统、MySQL 本身多维度分析，可能原因包括：
  1. 系统层面：硬件故障、负载过高（CPU/IOWAIT/SWAP/中断）；
  2. MySQL 层面：连接/线程异常、DNS 反解析问题、垃圾 SQL 过多、InnoDB 线程排队、磁盘满、锁等待；
  3. 其他层面：redo/binlog 2PC 延迟、semi-sync delay、binlog group commit delay、purge lag、checkpoint lag。

## 19. mysql crash 了，怎么办
- **排查步骤**：
  1. 分析 error log，判断是否因触发 bug 导致 crash；
  2. 分析 error log，判断是否因 InnoDB Semaphore wait 过久导致 crash；
  3. 检查是否因数据页损坏导致 crash。
- **解决方案**：
  1. 通过 Google 或 MySQL 官方 bug 库查找解决方案；
  2. 分析日志，还原现场，找出根因；
  3. 修复数据页，导出数据重建表；
  4. 排查并修复硬件故障和系统故障。
